{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1389 entries, 0 to 1388\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1389 non-null   int64  \n",
      " 1   comp        1389 non-null   object \n",
      " 2   round       1389 non-null   object \n",
      " 3   venue       1389 non-null   object \n",
      " 4   result      1389 non-null   object \n",
      " 5   gf          1389 non-null   float64\n",
      " 6   ga          1389 non-null   float64\n",
      " 7   opponent    1389 non-null   object \n",
      " 8   xg          1389 non-null   float64\n",
      " 9   xga         1389 non-null   float64\n",
      " 10  poss        1389 non-null   float64\n",
      " 11  sh          1389 non-null   float64\n",
      " 12  sot         1389 non-null   float64\n",
      " 13  dist        1388 non-null   float64\n",
      " 14  fk          1389 non-null   float64\n",
      " 15  pk          1389 non-null   float64\n",
      " 16  pkatt       1389 non-null   float64\n",
      " 17  team        1389 non-null   object \n",
      "dtypes: float64(11), int64(1), object(6)\n",
      "memory usage: 195.5+ KB\n",
      "None\n",
      "   Unnamed: 0            comp        round venue result   gf   ga  \\\n",
      "0           1  Premier League  Matchweek 1  Away      L  0.0  1.0   \n",
      "1           2  Premier League  Matchweek 2  Home      W  5.0  0.0   \n",
      "2           3  Premier League  Matchweek 3  Home      W  5.0  0.0   \n",
      "3           4  Premier League  Matchweek 4  Away      W  1.0  0.0   \n",
      "4           6  Premier League  Matchweek 5  Home      D  0.0  0.0   \n",
      "\n",
      "         opponent   xg  xga  poss    sh   sot  dist   fk   pk  pkatt  \\\n",
      "0       Tottenham  1.9  1.3  64.0  18.0   4.0  16.9  1.0  0.0    0.0   \n",
      "1    Norwich City  2.7  0.1  67.0  16.0   4.0  17.3  1.0  0.0    0.0   \n",
      "2         Arsenal  3.8  0.1  80.0  25.0  10.0  14.3  0.0  0.0    0.0   \n",
      "3  Leicester City  2.9  0.8  61.0  25.0   8.0  14.0  0.0  0.0    0.0   \n",
      "4     Southampton  1.1  0.4  63.0  16.0   1.0  15.7  1.0  0.0    0.0   \n",
      "\n",
      "              team  \n",
      "0  Manchester City  \n",
      "1  Manchester City  \n",
      "2  Manchester City  \n",
      "3  Manchester City  \n",
      "4  Manchester City  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = 'G:/BK/TTKH/matches.csv'  # Thay bằng đường dẫn tới file của bạn\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Loại bỏ các cột không cần thiết\n",
    "columns_to_drop = [\"time\", \"referee\", \"match report\", \"notes\", \"attendance\", \"captain\",\"date\",\"day\",\"formation\",\"season\"]\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Kiểm tra dữ liệu sau khi loại bỏ\n",
    "print(data_cleaned.info())\n",
    "print(data_cleaned.head())\n",
    "\n",
    "# Lưu dữ liệu đã xử lý ra file mới (nếu cần)\n",
    "data_cleaned.to_csv('cleaned_matches.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1111, 11)\n",
      "Shape of y_train: (1111, 2)\n",
      "Shape of X_test: (278, 11)\n",
      "Shape of y_test: (278, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "# 1. Xử lý giá trị thiếu\n",
    "data_cleaned['dist'] = data_cleaned['dist'].fillna(data_cleaned['dist'].mean())\n",
    "# 2. Mã hóa dữ liệu phân loại\n",
    "categorical_cols = ['comp', 'round', 'venue', 'result', 'opponent', 'team']\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    data_cleaned[col] = label_encoders[col].fit_transform(data_cleaned[col])\n",
    "\n",
    "# 3. Chọn các cột đầu vào và đầu ra\n",
    "X = data_cleaned[['xg', 'xga', 'poss', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt', 'opponent', 'team']]\n",
    "y = data_cleaned[['gf', 'ga']]\n",
    "\n",
    "# 4. Chuẩn hóa dữ liệu số\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 5. Chia dữ liệu thành tập train và test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6,\n",
    "          wires):  \n",
    "   \n",
    "    qml.U3(*weights_0, wires=wires[0])\n",
    "    qml.U3(*weights_1, wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(weights_2, wires=wires[0])\n",
    "    qml.RZ(weights_3, wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(weights_4, wires=wires[0])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.U3(*weights_5, wires=wires[0])\n",
    "    qml.U3(*weights_6, wires=wires[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập số lượng qubits và mạch lượng tử\n",
    "n_qubits = 10\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Định nghĩa các tham số của mạch lượng tử\n",
    "weight_shapes_QC = {\n",
    "    \"weights_0\": 3,\n",
    "    \"weights_1\": 3,\n",
    "    \"weights_2\": 1,\n",
    "    \"weights_3\": 1,\n",
    "    \"weights_4\": 1,\n",
    "    \"weights_5\": 3,\n",
    "    \"weights_6\": 3,\n",
    "}\n",
    "\n",
    "# Mạch lượng tử\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6):\n",
    "    \"\"\"\n",
    "    Định nghĩa mạch lượng tử cho mô hình HQCNN.\n",
    "    \"\"\"\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))  # Embedding dữ liệu vào mạch lượng tử\n",
    "    \n",
    "    # Sử dụng mạch U_SU4 trên các qubits\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[0, 1])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[2, 3])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[4, 5])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[6, 7])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[8, 9])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[1, 2])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[3, 4])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[5, 6])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[7, 8])\n",
    "    U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[9, 0])\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HQCNN(nn.Module):\n",
    "    def __init__(self, input_dim, qnode, weight_shapes, n_qubits):\n",
    "        super(HQCNN, self).__init__()\n",
    "        self.clayer_1 = nn.Linear(input_dim, n_qubits)  # Lớp chuyển đổi dữ liệu vào mạch lượng tử\n",
    "        self.qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)  # Lớp lượng tử\n",
    "        self.clayer_2 = nn.Linear(n_qubits, 2)  # Lớp đầu ra: [gf, ga]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clayer_1(x)\n",
    "        x = self.qlayer(x)\n",
    "        x = self.clayer_2(x)\n",
    "        return x\n",
    "if not isinstance(X_train, torch.Tensor):\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "if not isinstance(y_train, torch.Tensor):\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "if not isinstance(X_test, torch.Tensor):\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "if not isinstance(y_test, torch.Tensor):\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 3.444610595703125\n",
      "Epoch 2/100, Loss: 3.2215120792388916\n",
      "Epoch 3/100, Loss: 3.0106160640716553\n",
      "Epoch 4/100, Loss: 2.8146443367004395\n",
      "Epoch 5/100, Loss: 2.6347124576568604\n",
      "Epoch 6/100, Loss: 2.470459222793579\n",
      "Epoch 7/100, Loss: 2.321561574935913\n",
      "Epoch 8/100, Loss: 2.1882877349853516\n",
      "Epoch 9/100, Loss: 2.07077956199646\n",
      "Epoch 10/100, Loss: 1.9687020778656006\n",
      "Epoch 11/100, Loss: 1.8812808990478516\n",
      "Epoch 12/100, Loss: 1.807360053062439\n",
      "Epoch 13/100, Loss: 1.745481252670288\n",
      "Epoch 14/100, Loss: 1.693949818611145\n",
      "Epoch 15/100, Loss: 1.6509658098220825\n",
      "Epoch 16/100, Loss: 1.6147334575653076\n",
      "Epoch 17/100, Loss: 1.5835851430892944\n",
      "Epoch 18/100, Loss: 1.5560648441314697\n",
      "Epoch 19/100, Loss: 1.5309845209121704\n",
      "Epoch 20/100, Loss: 1.5074548721313477\n",
      "Epoch 21/100, Loss: 1.4848917722702026\n",
      "Epoch 22/100, Loss: 1.4629955291748047\n",
      "Epoch 23/100, Loss: 1.4417121410369873\n",
      "Epoch 24/100, Loss: 1.421157956123352\n",
      "Epoch 25/100, Loss: 1.401536226272583\n",
      "Epoch 26/100, Loss: 1.383047342300415\n",
      "Epoch 27/100, Loss: 1.3658140897750854\n",
      "Epoch 28/100, Loss: 1.3498235940933228\n",
      "Epoch 29/100, Loss: 1.33488929271698\n",
      "Epoch 30/100, Loss: 1.3206381797790527\n",
      "Epoch 31/100, Loss: 1.3065710067749023\n",
      "Epoch 32/100, Loss: 1.2921725511550903\n",
      "Epoch 33/100, Loss: 1.2770678997039795\n",
      "Epoch 34/100, Loss: 1.2611429691314697\n",
      "Epoch 35/100, Loss: 1.244591474533081\n",
      "Epoch 36/100, Loss: 1.227855920791626\n",
      "Epoch 37/100, Loss: 1.211509108543396\n",
      "Epoch 38/100, Loss: 1.1960939168930054\n",
      "Epoch 39/100, Loss: 1.1819864511489868\n",
      "Epoch 40/100, Loss: 1.1692938804626465\n",
      "Epoch 41/100, Loss: 1.1578369140625\n",
      "Epoch 42/100, Loss: 1.1472241878509521\n",
      "Epoch 43/100, Loss: 1.1369926929473877\n",
      "Epoch 44/100, Loss: 1.1267751455307007\n",
      "Epoch 45/100, Loss: 1.11641263961792\n",
      "Epoch 46/100, Loss: 1.105983853340149\n",
      "Epoch 47/100, Loss: 1.0957345962524414\n",
      "Epoch 48/100, Loss: 1.0859516859054565\n",
      "Epoch 49/100, Loss: 1.0768251419067383\n",
      "Epoch 50/100, Loss: 1.0683609247207642\n",
      "Epoch 51/100, Loss: 1.0603805780410767\n",
      "Epoch 52/100, Loss: 1.0526117086410522\n",
      "Epoch 53/100, Loss: 1.044818639755249\n",
      "Epoch 54/100, Loss: 1.0369234085083008\n",
      "Epoch 55/100, Loss: 1.0290336608886719\n",
      "Epoch 56/100, Loss: 1.0213865041732788\n",
      "Epoch 57/100, Loss: 1.0142155885696411\n",
      "Epoch 58/100, Loss: 1.0076416730880737\n",
      "Epoch 59/100, Loss: 1.0016143321990967\n",
      "Epoch 60/100, Loss: 0.9959623217582703\n",
      "Epoch 61/100, Loss: 0.9904986023902893\n",
      "Epoch 62/100, Loss: 0.9851260185241699\n",
      "Epoch 63/100, Loss: 0.97987300157547\n",
      "Epoch 64/100, Loss: 0.9748441576957703\n",
      "Epoch 65/100, Loss: 0.9701370596885681\n",
      "Epoch 66/100, Loss: 0.9657679200172424\n",
      "Epoch 67/100, Loss: 0.9616675972938538\n",
      "Epoch 68/100, Loss: 0.9577354192733765\n",
      "Epoch 69/100, Loss: 0.953914999961853\n",
      "Epoch 70/100, Loss: 0.9502227902412415\n",
      "Epoch 71/100, Loss: 0.9467238187789917\n",
      "Epoch 72/100, Loss: 0.9434740543365479\n",
      "Epoch 73/100, Loss: 0.9404675960540771\n",
      "Epoch 74/100, Loss: 0.9376461505889893\n",
      "Epoch 75/100, Loss: 0.9349366426467896\n",
      "Epoch 76/100, Loss: 0.9323050379753113\n",
      "Epoch 77/100, Loss: 0.9297692179679871\n",
      "Epoch 78/100, Loss: 0.9273733496665955\n",
      "Epoch 79/100, Loss: 0.9251428842544556\n",
      "Epoch 80/100, Loss: 0.9230647087097168\n",
      "Epoch 81/100, Loss: 0.9210962057113647\n",
      "Epoch 82/100, Loss: 0.9192042946815491\n",
      "Epoch 83/100, Loss: 0.9173887372016907\n",
      "Epoch 84/100, Loss: 0.9156752228736877\n",
      "Epoch 85/100, Loss: 0.9140846133232117\n",
      "Epoch 86/100, Loss: 0.9126118421554565\n",
      "Epoch 87/100, Loss: 0.9112271070480347\n",
      "Epoch 88/100, Loss: 0.9099001884460449\n",
      "Epoch 89/100, Loss: 0.9086207747459412\n",
      "Epoch 90/100, Loss: 0.9073969721794128\n",
      "Epoch 91/100, Loss: 0.9062404036521912\n",
      "Epoch 92/100, Loss: 0.9051485657691956\n",
      "Epoch 93/100, Loss: 0.9041041731834412\n",
      "Epoch 94/100, Loss: 0.9030917882919312\n",
      "Epoch 95/100, Loss: 0.9021104574203491\n",
      "Epoch 96/100, Loss: 0.9011682868003845\n",
      "Epoch 97/100, Loss: 0.9002742767333984\n",
      "Epoch 98/100, Loss: 0.8994235992431641\n",
      "Epoch 99/100, Loss: 0.898605465888977\n",
      "Epoch 100/100, Loss: 0.8978106379508972\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình\n",
    "input_dim = X_train.shape[1]\n",
    "model = HQCNN(input_dim, qnode, weight_shapes_QC, n_qubits)\n",
    "\n",
    "# Cấu hình huấn luyện\n",
    "criterion = nn.MSELoss()  # Hàm mất mát\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Bộ tối ưu hóa\n",
    "epochs = 100\n",
    "\n",
    "# Huấn luyện\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_score_qcnn(team_1, team_2, model, data_cleaned, scaler, label_encoders):\n",
    "    \"\"\"\n",
    "    Dự đoán tỷ số giữa hai đội bằng mô hình Quantum CNN với dữ liệu có sẵn.\n",
    "    \n",
    "    Parameters:\n",
    "        team_1 (str): Tên đội chủ nhà.\n",
    "        team_2 (str): Tên đội khách.\n",
    "        model (HQCNN): Mô hình đã huấn luyện.\n",
    "        data_cleaned (pd.DataFrame): Dữ liệu đã tiền xử lý.\n",
    "        scaler (StandardScaler): Bộ chuẩn hóa dữ liệu.\n",
    "        label_encoders (dict): Bộ mã hóa cho các cột phân loại.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (gf, ga) - Tỷ số dự đoán giữa hai đội.\n",
    "    \"\"\"\n",
    "    # Mã hóa tên đội\n",
    "    if team_1 not in label_encoders['team'].classes_ or team_2 not in label_encoders['team'].classes_:\n",
    "        raise ValueError(\"Tên đội không tồn tại trong dữ liệu!\")\n",
    "    \n",
    "    team_1_encoded = label_encoders['team'].transform([team_1])[0]\n",
    "    team_2_encoded = label_encoders['team'].transform([team_2])[0]\n",
    "    team_1_history = data_cleaned[data_cleaned['team'] == team_1_encoded]\n",
    "    team_2_history = data_cleaned[data_cleaned['team'] == team_2_encoded]\n",
    "\n",
    "    if team_1_history.empty or team_2_history.empty:\n",
    "        raise ValueError(\"Không có đủ dữ liệu lịch sử cho một trong hai đội!\")\n",
    "    team_1_sample = team_1_history.sample(n=1, random_state=random.randint(0, 1000)).iloc[0]\n",
    "    team_2_sample = team_2_history.sample(n=1, random_state=random.randint(0, 1000)).iloc[0]\n",
    "    input_data = {\n",
    "        'xg': team_1_sample['xg'],\n",
    "        'xga': team_2_sample['xga'],\n",
    "        'poss': (team_1_sample['poss'] + team_2_sample['poss']) / 2,\n",
    "        'sh': (team_1_sample['sh'] + team_2_sample['sh']) / 2,\n",
    "        'sot': (team_1_sample['sot'] + team_2_sample['sot']) / 2,\n",
    "        'dist': (team_1_sample['dist'] + team_2_sample['dist']) / 2,\n",
    "        'fk': (team_1_sample['fk'] + team_2_sample['fk']) / 2,\n",
    "        'pk': (team_1_sample['pk'] + team_2_sample['pk']) / 2,\n",
    "        'pkatt': (team_1_sample['pkatt'] + team_2_sample['pkatt']) / 2,\n",
    "        'opponent': team_2_encoded,\n",
    "        'team': team_1_encoded\n",
    "    }\n",
    "\n",
    "    # Chuẩn hóa đầu vào\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "    input_tensor = torch.tensor(input_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Dự đoán\n",
    "    model.eval()  # Đặt mô hình ở chế độ đánh giá\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor)\n",
    "    \n",
    "    predicted_gf, predicted_ga = prediction[0][0].item(), prediction[0][1].item()\n",
    "    return round(predicted_gf), round(predicted_ga)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brighton and Hove Albion 1-3 Crystal Palace\n",
      "Brighton and Hove Albion 1-3 Crystal Palace\n",
      "Brighton and Hove Albion 1-3 Crystal Palace\n",
      "Brighton and Hove Albion 1-0 Crystal Palace\n",
      "Brighton and Hove Albion 1-3 Crystal Palace\n",
      "Brighton and Hove Albion 2-1 Crystal Palace\n",
      "Brighton and Hove Albion 0-3 Crystal Palace\n",
      "Brighton and Hove Albion 1-0 Crystal Palace\n",
      "Brighton and Hove Albion 2-0 Crystal Palace\n",
      "Brighton and Hove Albion 1-1 Crystal Palace\n",
      "Tỷ số trung bình: Brighton and Hove Albion 1 - 1 Crystal Palace\n",
      "Tỷ lệ thắng: Brighton and Hove Albion: 40.00%, Crystal Palace: 50.00%, Hòa: 10.00%\n"
     ]
    }
   ],
   "source": [
    "team_1 = \"Brighton and Hove Albion\"\n",
    "team_2 = \"Crystal Palace\"\n",
    "\n",
    "# Vòng lặp dự đoán\n",
    "results = []\n",
    "team_1_wins = 0\n",
    "team_2_wins = 0\n",
    "draws = 0\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        # Dự đoán tỷ số\n",
    "        predicted_score = predict_score_qcnn(team_1, team_2, model, data_cleaned, scaler, label_encoders)\n",
    "        result = {\n",
    "            \"Team 1\": team_1,\n",
    "            \"Team 2\": team_2,\n",
    "            \"Score\": f\"{predicted_score[0]}-{predicted_score[1]}\"\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"{team_1} {predicted_score[0]}-{predicted_score[1]} {team_2}\")\n",
    "        \n",
    "        # Xác định kết quả thắng, thua hoặc hòa\n",
    "        if predicted_score[0] > predicted_score[1]:\n",
    "            team_1_wins += 1\n",
    "        elif predicted_score[0] < predicted_score[1]:\n",
    "            team_2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "    except ValueError as e:\n",
    "        print(f\"Lỗi dự đoán: {e}\")\n",
    "\n",
    "# Tính trung bình tỷ số và tỷ lệ thắng\n",
    "if results:\n",
    "    total_score_team_1 = 0\n",
    "    total_score_team_2 = 0\n",
    "    \n",
    "    for result in results:\n",
    "        score_team_1, score_team_2 = map(int, result[\"Score\"].split(\"-\"))\n",
    "        total_score_team_1 += score_team_1\n",
    "        total_score_team_2 += score_team_2\n",
    "    \n",
    "    avg_score_team_1 = int(total_score_team_1 / len(results))\n",
    "    avg_score_team_2 = int(total_score_team_2 / len(results))\n",
    "    \n",
    "    # Tính tỷ lệ thắng\n",
    "    total_matches = len(results)\n",
    "    win_rate_team_1 = team_1_wins / total_matches * 100\n",
    "    win_rate_team_2 = team_2_wins / total_matches * 100\n",
    "    draw_rate = draws / total_matches * 100\n",
    "\n",
    "    # Hiển thị kết quả\n",
    "    print(f\"Tỷ số trung bình: {team_1} {avg_score_team_1} - {avg_score_team_2} {team_2}\")\n",
    "    print(f\"Tỷ lệ thắng: {team_1}: {win_rate_team_1:.2f}%, {team_2}: {win_rate_team_2:.2f}%, Hòa: {draw_rate:.2f}%\")\n",
    "else:\n",
    "    print(\"Không có kết quả dự đoán hợp lệ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arsenal' 'Aston Villa' 'Brentford' 'Brighton and Hove Albion' 'Burnley'\n",
      " 'Chelsea' 'Crystal Palace' 'Everton' 'Fulham' 'Leeds United'\n",
      " 'Leicester City' 'Liverpool' 'Manchester City' 'Manchester United'\n",
      " 'Newcastle United' 'Norwich City' 'Sheffield United' 'Southampton'\n",
      " 'Tottenham Hotspur' 'Watford' 'West Bromwich Albion' 'West Ham United'\n",
      " 'Wolverhampton Wanderers']\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    # Tạo DataFrame từ kết quả mới\n",
    "    new_data = pd.DataFrame(results)\n",
    "    \n",
    "    # Nếu file đã tồn tại, đọc nội dung cũ và nối dữ liệu mới vào\n",
    "    if os.path.exists(file_path):\n",
    "        existing_data = pd.read_excel(file_path)\n",
    "        all_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "    else:\n",
    "        all_data = new_data\n",
    "    \n",
    "    # Ghi vào file\n",
    "    all_data.to_excel(file_path, index=False, engine='openpyxl')\n",
    "    print(f\"Đã lưu {len(results)} kết quả mới vào {file_path}\")\n",
    "else:\n",
    "    print(\"Không có kết quả để lưu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
